#+title: Tiebreaking Strategies for A* Search: How to Explore the
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg

#+BEGIN_outline-text-1

#+BEGIN_CENTER
[[png:final-frontier]]
#+END_CENTER

#+BEGIN_CENTER
_Masataro Asai_, Alex Fukunaga

University of Tokyo

Presented in JSAI-16, Jun 6, 2016

Presented in AAAI-16, Feb 15 2016
#+END_CENTER

#+BEGIN_RESUME
さてこんにちは、東京大学の浅井と申します。
今日は教科書にも載っていて誰でも知っているはずのグラフ探索手法、A*アルゴリズムの改良についてお話します。
#+END_RESUME
#+END_outline-text-1

* 先に結果: /A*の性能をタイブレーキングを変えるだけで改善!!/

#+BEGIN_CENTER
1724問中、4GBメモリ制限で5分以内に解けた問題の数
#+END_CENTER

|                         | <c>              | <c>         |
|                         | Default          | 提案手法    |
| 問題セット              | in Fast Downward |             |
|-------------------------+------------------+-------------|
| IPC^1 Instances (1104)  | 558              | *573*       |
| Zerocost Instances(680) | 256              | *294*       |
| Sum (1724)              | 814              | *867* (+53) |
|-------------------------+------------------+-------------|

IPC^1 : International Planning Competition で使われる 高次元グラフ探索ベンチマーク

(35種類の問題集)×(20〜50問)

それぞれの問題集は全く異なる性質の *最適化問題をモデル化*

*問題番号が進むと 指数的に難しくなる*

#+BEGIN_ALIGNRIGHT
*53問 多く解ける = スゴイ速い*
#+END_ALIGNRIGHT

#+BEGIN_RESUME
先に結果を話します。やったことは、State-of-the-Artを改善したということです。
コンペティションで用いられる高次元グラフ探索のベンチマーク1724問中、
4GBメモリ制限で5分以内に解けた問題の数を比べます。
ベンチマークは35種類の問題集からなり、それぞれの問題集は20から50問の問題からなります。
それぞれの問題集は全く異なる性質の *最適化問題をモデル化* しています。
また、 *問題番号が進むと 指数的に難しくなる* 性質があります。
従って、53問 多く解けるということは一言で言えば スゴイ速い ということです。

まあこれだとちょっと飛ばしすぎましたので、よりバックグラウンドについて丁寧にお話をします。
#+END_RESUME

* Main Topic : Optimal Graph Search

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN7

[[png:graphsearch]]
#+END_SPAN7
#+BEGIN_SPAN5

#+BEGIN_LARGER
#+BEGIN_CENTER
*Shortest path*

from the *Initial Node*

to the *Goal Node(s)*
#+END_CENTER
#+END_LARGER

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_RESUME
The main topic of my talk is the optimal graph search problem whose task is
to find a optimal or shortest path from the initial state to the goal
state. I don't know why my presentation is in the planning session.
#+END_RESUME

# * Dijkstra
# 
# [[png:dijkstra]]

* Optimal Search with A* ...

# Guaranteed to find an optimal solution when /heuristic function/ $h(s)$ is admissible

[[png:astar]]

#+BEGIN_RESUME
currently, the most prevarent method for optimal graph search is A* algorithm.
In A*, a node has g-value, which is the current shortest cost from the initial state,
and h-value, which is a result of a heuristic function h, which should be admissible in the optimal search.
Their sum, f, is a lower bound of the cost of the shortest path, f*.

In order to prove optimality,
A* is required to expand all nodes whose f is smaller than f*.  Due to this
requirement, A* expands the nodes with the smallest f value each time.

However, this description lacks one important aspect of A*.
#+END_RESUME

* Optimal Search with A* ... w/o Tiebreaking Strategy.

# Guaranteed to find an optimal solution when /heuristic function/ $h(s)$ is admissible

[[png:astar-emph]]

#+BEGIN_RESUME
The aspect is the tiebreaking strategy. What happens when more than 2 nodes
have the same f-minimum? In such cases, a tiebreaking strategy should select which node to expand.
#+END_RESUME

* Conventional Wisdom regarding Tiebreaking

#+BEGIN_CENTER
How to select from multiple nodes with the same /f_{min}/?
#+END_CENTER

|                                  | Tiebreaking                                 |
|----------------------------------+---------------------------------------------|
| *Early work*                     |                                             |
| /1968 Hart, Nilsson and Raphael/ | */h/-based tiebreaking* [ /h/ ] :           |
|                                  | 　　 -- selects the least h value           |
| /common around 1985/             | *LIFO tiebreaking* [LIFO] :                 |
|                                  | 　　 -- selects the most recently generated |
|----------------------------------+---------------------------------------------|
| *Recent years...*                |                                             |
| /2007 Hansen and Zhou/           | [ /h/ ] "well-known to achieve              |
|                                  | 　　　　　　the best performance"           |
| /2010 Holte/                     | [ /h/ ] "most often done"                   |
|----------------------------------+---------------------------------------------|

#+BEGIN_ALIGNRIGHT
*Rule-of-Thumb is [ /h/ ] but it's like a folklore!*
#+END_ALIGNRIGHT

#+BEGIN_RESUME
There are several conventional wisdoms on the tiebreaking of A*.

In the earliest work, 
the original paper on A* by Hart, Nilsson and Raphael
proposed a strategy of selecting the nodes with the least h value.
We call this tiebreaking as h-based tiebreaking, and use the notation surrounded by brackets.

Another important method is LIFO tiebreaking, which expands a node in most-recently-generated-first.
It seems to be common already in 1985.

In recent years, we rarely find a detailed description on tiebreaking.
It is sometimes said: it's known to perform well or it's common.
There are sometimes no mention at all.

Overall, it seems that the current rule-of-thumb is to use h-based tiebreaking.
#+END_RESUME

* [ /h/ ] is underspecified

*What happens if there are still /multiple/ nodes with the same /h/ ?*

→ There must be a *2nd Tiebreaking /X/* : denoted as [ /h/ , */X/* ]

Example -- A* with *[ /h/ , /LIFO/ ]* : Selects the nodes with /f_{min}/. 

+ *IF* multiple nodes have /f_{min}/, selects the nodes with /h_{min}/  (1st tiebreaking).
+ *IF* multiple nodes have /h_{min}/, select the most recent node (2nd tiebreaking).
  #+BEGIN_ALIGNRIGHT
  #+BEGIN_SMALLER
  (i.e. popping a LIFO queue: always returns exactly 1 node)
  #+END_SMALLER
  #+END_ALIGNRIGHT

|-----------------------------------------------+---------------------------------|
| Solver code on github by /2012 Burns et. al./ | [ /h/, LIFO (*not documented*)] |
| (current) Fast Downward                       | [ /h/, FIFO (*not documented*)] |
|-----------------------------------------------+---------------------------------|

#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
+ Details (such as 2nd-tiebreaking /X/) are *considered unimportant?*

  (compared to the improvement of the heuristics, search algorithm?)
#+END_LARGER
#+END_ALIGNRIGHT


#+BEGIN_RESUME
However, h-based tiebreaking has a severe problem that it is still underspecified.
What happens if there are still multiple nodes with the same h?
There should be some further tiebreaking criteria which selects exactly one node among them.
In most papers, this kind of detail is not mentioned at all.

We found that the implementation by burns et. al. uses h-based tiebreaking followed by LIFO tiebreaking,
and the current fast downward uses h-based tiebreaking followed by FIFO tiebreaking.
Both of these are not specified in the paper.
In other words, these details are not considered important.
#+END_RESUME

* TODO In Fact, Tiebreaking is Quite Important

#+BEGIN_LARGER
#+BEGIN_CENTER
*Most of the runtime, search is controlled*

 */solely by the tiebreaking/.*
#+END_CENTER
#+END_LARGER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
[[png:without-h-nokey]]
#+END_SPAN6
#+BEGIN_SPAN6

←In the standard benchmark sets,

#+BEGIN_LARGER
#+BEGIN_CENTER
*Most nodes have f=f^**.

(i.e. *Final Plateau*, 　　

where the solutions exist)
#+END_CENTER

　

#+BEGIN_CENTER
*Tiebreaking controls the most of the search.*
#+END_CENTER
#+END_LARGER
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_RESUME
However, tiebreaking is actually quite important.
We plotted the number of nodes whose f value is equal to f*,
versus those with f value less than equal to f*,

In this figure, we can see that the most nodes have the f value equal to f*.
We call these nodes as the final plateau.

The final plateau is where the optimal solutions exist.
And where all nodes have the same f-value.

Thus, in this plateau,
the search is controlled solely by the tiebreaking.
#+END_RESUME

* Testing if the 2nd Tiebreaking Really Matters

| <c>                           | <c>                               | <c>       |
| Tiebreaking                   | Description                       | Solved    |
| ［criterion_1, criterion_2 ］ | (applied in left-to-right)        | Instances |
|-------------------------------+-----------------------------------+-----------|
| ［ /h/,  *LIFO* ］            | same /f_{min}/ → select smallest h |           |
|                               | same h → break ties in LIFO      |           |
|-------------------------------+-----------------------------------+-----------|
| ［ /h/,  *FIFO* ］            | *default setting of FD*           |           |
|-------------------------------+-----------------------------------+-----------|

#+BEGIN_ALIGNRIGHT
on 1104 IPC (International Planning Competition) instances

30min, 2GB setting with the same heuristics (LMcut)

　

　

#+END_ALIGNRIGHT

#+BEGIN_RESUME
To further investigate the importance of tiebreaking behavior, we tested
two commonly used tiebreaking strategies, namely h-LIFO and h-FIFO.
h-fifo is the default setting of Fast Downward.

Each criterion is applied in a dictionary order.
For example, [h,fifo] means that,
if there are multiple nodes have the same f value, it selects the smallest h.
If there are still multiple nodes have the same h value, it breaks ties according to FIFO.

We tested these strategies on IPC instances.
#+END_RESUME

* Testing if the 2nd Tiebreaking Really Matters

# Results (on 1104 IPC instances,  LMcut, 30min, 2GB)

| <c>                           | <c>                               | <c>       |
| Tiebreaking                   | Description                       | Solved    |
| ［criterion_1, criterion_2 ］ | (applied in left-to-right)        | Instances |
|-------------------------------+-----------------------------------+-----------|
| ［ /h/, *LIFO* ］             | same /f_{min}/ → select smallest h | *565*     |
|                               | same h → break ties in LIFO      |           |
|-------------------------------+-----------------------------------+-----------|
| ［ /h/, *FIFO* ］             | *default setting of FD*           | 558       |
|-------------------------------+-----------------------------------+-----------|

#+BEGIN_ALIGNRIGHT
on 1104 IPC (International Planning Competition) instances

30min, 2GB setting with the same heuristics (LMcut)

#+BEGIN_LARGER
*［h, LIFO ］ outperforms ［h, FIFO ］*
#+END_LARGER

the 2nd tiebreaking makes difference
#+END_ALIGNRIGHT

#+BEGIN_RESUME
The result showed that ［h, LIFO ］ outperforms ［h, FIFO ］.  This is a
surprising result, considering that only the 2nd tiebreaking
difference caused such a difference.
#+END_RESUME

* TODO Comparing [h,FIFO] and [h,LIFO] per Domain (Instance Set)

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
[[png:lifo-vs-fifo]]
#+END_SPAN6
#+BEGIN_SPAN6

#+BEGIN_CENTER
The difference occurs only in

#+BEGIN_LARGER
*Openstacks* & *Cybersec*
#+END_LARGER

*LIFO is x10 faster than FIFO*

(In other domains the performance is comparable.)

#+END_CENTER
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_RESUME
what is the reason behind this?  From the domain-wise investigation, we
found that this is caused mainly by the Cybersec and Openstacks domains.

We plotted the number of evaluations by each strategy in x-y plot. As we
see, their difference is small in most domains except Openstacks
and Cybersec.
#+END_RESUME

* What makes /Openstacks/ & /Cybersec/ Different?

Many *zero-cost actions*

#+BEGIN_SMALLER
which (before proceeding, let me say...) enables
#+END_SMALLER

the modelling of many *practical applications* w/ *key resource minimization*

+ Consider a *transportation domain w/ fuel minimization.*
  #+BEGIN_ALIGNRIGHT
  Assign 0 cost to all actions *except drive-truck*

  which burns some fuel.
  #+END_ALIGNRIGHT
+ *Openstacks is an application domain* from Operations Research (Fink and Voss, 1999)
  #+BEGIN_ALIGNRIGHT
  minimize the # of stacks, 0-cost unless consuming stacks.
  #+END_ALIGNRIGHT
+ *Cybersec is also an application domain.* (BAMS, Boddy et. al.)
  #+BEGIN_ALIGNRIGHT
  The great talk by Joerg Hoffmann in the last ICAPS!
  #+END_ALIGNRIGHT

#+BEGIN_RESUME
These domains are characteristic by its large number of zero-cost actions.

Addressing the problem caused by zero-cost actions is important because it
frequently appears in practial application domains.

First of all, both of these domains originates from industrial applications.
Openstacks originates from Operations Resarch.
Regarding Cybersec, I hope the listeners remember the great talk by jorg hoffman in the last ICAPS.

Another interesting example is a realistic transportation domain with fuel optimization.
In such as setting, the domain will assign 0 to all action costs except drive-truck.
#+END_RESUME

* TODO Zero-cost actions makes /h/-Tiebreaking difficult

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
[[png:with-h-nokey]]
#+END_SPAN6
#+BEGIN_SPAN6

#+BEGIN_CENTER
← A stricter subset of final plateau with *f=f^**, *h=0*

In *Openstacks* & *Cybersec*,

Almost all nodes have *h=0*.

#+BEGIN_LARGER
*⇒ /h/-tiebreaking has*

*no effect*
#+END_LARGER

#+BEGIN_LARGER
*⇒search is controlled /solely by the 2nd tiebreaking/*

*/LIFO or FIFO/*
#+END_LARGER
#+END_CENTER
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
Thus, *to improve upon LIFO*, we should understand these search spaces.
#+END_ALIGNRIGHT

#+BEGIN_RESUME
Well, I didn't explained exaclty why these zero-cost made the difference.

These domains are unfriendly to h-based tiebreaking. This is a plot of the final plateau, with differnt definition.
This time, not only f is equal to f*, but also h should be equal to 0.

In openstacs and cybersec, almost all nodes are on the x-y line.
In other words, at almsot all search nodes, h=0.
In these domains, h-tiebreaking has almost no effect.

Thus, to improve upon LIFO, we should understand Final Plateau.
#+END_RESUME

# , and the LIFO and FIFO plays the primary role. 

* Understanding the Final Plateau

[[png:final-plateau0]]

#+BEGIN_RESUME
First of all, this is the traditional understanding of the search space of
A*. However, this is actually not the case, because
#+END_RESUME

* Understanding the Final Plateau

[[png:final-plateau]]

#+BEGIN_RESUME
in fact, most nodes are in the large final plateau.
This is the same whether it is positive or zero-cost.
Without proper tiebreaking strategy, the planner has no guidance,
because any heuristic estimates are the same almost everywhere.
#+END_RESUME

* Understanding the Final Plateau

In positive cost domains,

[[png:final-plateau2]]

#+BEGIN_RESUME
In positive-cost domains, the h-based tiebreaking is useful because it provides a gradient toward the goal.
#+END_RESUME

* But when almost all edges are 0-cost...

[[png:final-plateau3]]

#+BEGIN_RESUME
However, in zero-cost domains, almost all h values are 0, and h-based tiebreaking is useless.
The problem is, how can we give a useful guidance in such a region?
#+END_RESUME

* Depth-based Tiebreaking

[[png:final-plateau4]]

#+BEGIN_RESUME
Here, we propose a depth-based tiebreaking.

Depth characterises a number of steps from the entrance of the plateau.

If the parent of a node have the different f and h value, then the child is
a plateau entrance, and its depth is 0.

If the parent of a node have the same f and h value, then the child has a depth larger by one.
#+END_RESUME

* Non-trivial Question: How to use the /Depth?/

Assume h=0 (because 0≦h≦h^*=0)

Within Final Plateau f=f^*, *all solutions are cost optimal* regardless of depth

#+BEGIN_ALIGNRIGHT
because *all edge costs are 0.*
#+END_ALIGNRIGHT

[[png:final-plateau4-2]]

#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
We found that *DEPTH BIAS IS NOT A GOOD IDEA.*
#+END_LARGER
#+END_ALIGNRIGHT

#+BEGIN_RESUME
The next problem is how to use the depth.  In designing such a strategy, we
should note that within final plateau, any solutions are cost optimal
because all edge costs are 0.
In this context, introducing a bias in each depth is not a good idea.
#+END_RESUME

** Example: selecting the smallest depth?

# /FirstDepth/ tiebreaking strategy : ［ h, /fd/ ］

[[png:final-plateau5]]

#+BEGIN_RESUME
For example, what happens if we always prefer the smallest depth?
We call such a stratefy First Depth.
FirstDepth behaves like a breadth-first search and FIFO tiebreaking, which did not perform well.

FirstDepth tends to search the neighborhood of plateau entrance exhaustively,
and takes too much time to reach the appropriate depth.
#+END_RESUME

** Example: selecting the largest depth?

# /LastDepth/ tiebreaking strategy :  ［ h, /ld/ ］

[[png:final-plateau6]]

#+BEGIN_RESUME
The opposite scheme, LastDepth, also have a problem.  Last depth, which
always selects the largest depth, is in certain condition equivalent to
depth-first LIFO tiebreaking.
It may quickly pass and miss the important depth.
#+END_RESUME


* Random Depth Tiebreaking

[[png:final-plateau7]]

#+BEGIN_ALIGNRIGHT
Classic Exploration vs Exploitation problem

Connections to Rapidly exploring Random Tree (RRT) ?
#+END_ALIGNRIGHT

#+BEGIN_RESUME
Finally, we propose RandomDepth tiebreaking which removes the depth bias.
Actual implementation of RandomDepth is as follows.

When h-tiebreaking fails, RandomDepth selects a random depth.

Then a Random Order selects one node at random.

RandomDepth Tiebreaking can search the final plateau uniformly and sparsely.
This is an interesting aspect similar to Rapidly exploring Random Tree.
#+END_RESUME

# * Random Depth Tiebreaking + random selection within depth
# 
# third tiebreaking: not FIFO, not LIFO, but RandomOrder : RO
# 
# ［ h, /rd/, RO ］
# 
# [[png:final-plateau7]]

* Evaluation (domains)

+ IPC^1 Instances (1104 instances)
+ *Zero-cost* domains (620 instances, 28 domains)
  + Modified IPC^1  optimal track instances
  + Assign 0 cost to all actions *except one*
  + which consumes a *realistic key resource*. For example,
    + =cut= consumes =wood= in Woodworking
    + =drive-truck= consumes =fuel= in Driverslog (transportation domain)
    + etc..

#+BEGIN_NOTE
1 -- IPC : International Planning Competition
#+END_NOTE

#+BEGIN_RESUME
Finally, the experimental evaluation.  Along with the original IPC
instances, we introduce Zero-cost domains, which are the instances we
assigned cost 0 to all actiosn except one.

The one which has a positive cost represents a realistic key resource,
such as wood, fuel or electricity.

We created 620 zerocost instances consisting of 28 domains.
#+END_RESUME

* Evaluation (participants)


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
A* with *[h, FIFO]*

Selects the nodes with /f_{min}/

*IF* multiple nodes have /f_{min}/

Selects the nodes with /h_{min}/

*IF* multiple nodes have /h_{min}/

Select the oldest node (i.e. FIFO)
#+END_SPAN6
#+BEGIN_SPAN6
A* with *[h, LIFO]*

Selects the nodes with /f_{min}/

*IF* multiple nodes have /f_{min}/

Selects the nodes with /h_{min}/

*IF* multiple nodes have /h_{min}/

Select the newest node (i.e. LIFO)
#+END_SPAN6
#+END_ROW-FLUID

-----------

#+BEGIN_ROW-FLUID
#+BEGIN_SPAN1

#+END_SPAN1
#+BEGIN_SPAN10
A* with *[h, RD, RO]*,

Selects the nodes with /f_{min}/

*IF* multiple nodes have /f_{min}/, selects the nodes with /h_{min}/

*IF* multiple nodes have /h_{min}/, selects a random depth /d/

*IF* multiple nodes in /d/, Select a node randomly
#+END_SPAN10
#+BEGIN_SPAN1

#+END_SPAN1
#+END_ROW-FLUID
#+END_CONTAINER-FLUID


#+BEGIN_RESUME
Now lets review the participants.  [h, FIFO] is a conventional
tiebreaking strategy which first break ties according to h, When there are
multiple nodes with the same h, it then breaks ties accoding to the FIFO
order, in other words expanding the oldest node.

[h, LIFO] is another conventional tiebreaking strategy which also uses
h-tiebreaking, but when there are multiple nodes with the same h,
it expands in LIFO order, or expanding the most recently generated node first.

Finally, [h, RD, RO] is our proposed method. It also uses the h-based
tiebreaking.  However, when multiple nodes have the same h, it puts them
into several buckets according to the depth d, then select a bucket at
random. From the selected bucket, it selects a node at random.
#+END_RESUME

* Evaluation (number of problems solved)

#+BEGIN_SMALLER
LMcut, Merge-and-Shrink(M&S) : state-of-the-art heuristic functions in planning

［h, RD, RO］ shows the average of 10 runs (↑ ＜increase over [h,FIFO]＞)
#+END_SMALLER

| /                       | <            | >           | <>                |
|                         | <c>          | <c>         | <c>               |
|                         | ［h, FIFO］  | ［h, LIFO］ | ［h, RD, RO］     |
| Domain Set              | (FD Default) |             | (Proposed)        |
|-------------------------+--------------+-------------+-------------------|
| LMcut                   |              |             |                   |
| IPC Instances (1104)    |              |             |                   |
| Zerocost Instances(680) |              |             |                   |
| Sum(1724)               |              |             |                   |
|-------------------------+--------------+-------------+-------------------|
| M&S                     |              |             |                   |
| IPC Instances (1104)    |              |             |                   |
| Zerocost Instances(680) |              |             |                   |
| Sum(1724)               |              |             |                   |
|-------------------------+--------------+-------------+-------------------|

#+BEGIN_RESUME
We tested these tiebreakings with a standard competition setting of 30 min,
2GB memory.  We used both the LMcut heuristics and Merge-and-Shrink
heuristics, which are both the state-of-the-arts but
whose values are computed in a completely different manner.
#+END_RESUME

* Evaluation (number of problems solved)

#+BEGIN_SMALLER
LMcut, Merge-and-Shrink(M&S) : state-of-the-art heuristic functions in planning

［h, RD, RO］ shows the average of 10 runs (↑ ＜increase over [h,FIFO]＞)
#+END_SMALLER

| /                       | <            | >           | <>                |
|                         | <c>          | <c>         | <c>               |
|                         | ［h, FIFO］  | ［h, LIFO］ | ［h, RD, RO］     |
| Domain Set              | (FD Default) |             | (Proposed)        |
|-------------------------+--------------+-------------+-------------------|
| LMcut                   |              |             |                   |
| IPC Instances (1104)    | 558          | 565         | *572.8* (↑ 14.8) |
| Zerocost Instances(680) | 256          | 279         | *294.2* (↑ 38.2) |
| Sum(1724)               | 814          | 844         | *867.0* (↑ 53.0) |
|-------------------------+--------------+-------------+-------------------|
| M&S                     |              |             |                   |
| IPC Instances (1104)    | 479          | *488*       | 484.0 (↑ 5.0)    |
| Zerocost Instances(680) | 276          | 290         | *310.2* (↑ 34.2) |
| Sum(1724)               | 755          | 778         | *794.2* (↑ 39.2) |
|-------------------------+--------------+-------------+-------------------|

#+BEGIN_ALIGNRIGHT
*［h, RD, RO］ Outperformed Both [h,FIFO] and [h,LIFO] !*
#+END_ALIGNRIGHT

#+BEGIN_RESUME
And this is the result. We achieved a
significant improvement both in the IPC instances and in Zerocost instances.
#+END_RESUME

* Depth Distribution in Woodworking-cut p04

"cut" action has positive cost (consumes wood), others have 0 cost

#+BEGIN_CENTER
  
[[png:depth-distribution0]]

#+END_CENTER

#+BEGIN_RESUME
Next, in order to see our plateau theory actually holds,
we plotted the number of nodes in each depth.
#+END_RESUME

* Depth Distribution in Woodworking-cut p04

"cut" action has positive cost (consumes wood), others have 0 cost

#+BEGIN_CENTER
  
[[png:depth-distribution1]]

#+END_CENTER

#+BEGIN_RESUME
Now we can first see FIFO is too biased toward the shallower region.
#+END_RESUME

* Depth Distribution in Woodworking-cut p04

"cut" action has positive cost (consumes wood), others have 0 cost

#+BEGIN_CENTER
  
[[png:depth-distribution2]]

#+END_CENTER

#+BEGIN_RESUME
And LIFO is too biased toward the deeper region.
#+END_RESUME

* Depth Distribution in Woodworking-cut p04

"cut" action has positive cost (consumes wood), others have 0 cost

#+BEGIN_CENTER
  
[[png:depth-distribution3]]

#+END_CENTER

#+BEGIN_RESUME
In contrast the distribution of RandomDepth draws a beautiful curve,
showing that it distributes its effort among different depths.
#+END_RESUME

* Contributions

+ *In-depth analysis of the tiebreaking strategies*
  + The paper contains more analyses
    + ([h,FIFO] vs [FIFO], [h,RD,RO] vs [h,RO] etc.)
+ *Randomized depth-based tiebreaking* in zero-cost domains
  + *no heuristics can help* because the optimal cost is 0
+ *Understanding of the structure of the final plateau*
  + *Depth Bias is harmful* -- exploration vs exploitation

* Future Work -- Connections to the Other Areas

+ It would be applicable to Bidi search (*Award Talk*)
+ Satisficing Search ( cf. *Yesterday talk by Richard Valenzano* )
  + Use *ｆ／５* -- most actions become 0 cost
    + looks like constant-error search (/＜ｆ^*+5/) unlike WA* : /＜w×ｆ^*/ 
+ Temporal Planning/Scheduling
  + Short actions do not increase the makespan = 0-cost actions?
+ Can we make the exploration more efficient?
  + *RRTs* (Rapidly exploring Random Trees) + diversity metric
  + *MCTS* (Monte Carlo Tree Search w/ Upper Confidence Bound)
+ "Plan Diversity is underinvestigated" --- Jorg Hoffman
  + Exploration-based approach might also be underinvestigated?

#+BEGIN_CENTER
Thanks for your attention!
#+END_CENTER

* Appendix

+ Is randomness necessary? How about just round-robin loop?
  + I consider it is possible but not tested yet.
+ Relationship to LA^*_0 and LAMA's PLUSONE cost type? (lookahead)
  + LA^*_0 is equivalent to FIFO, the smallest depth.
  + PLUSONE is FIFO, and is inadmissible.
+ Little disadvantage in positive-cost domains (depth is always 0)
  + except: slows down expansion rate in M&S
    + M&S eval is table lookup and quite fast

